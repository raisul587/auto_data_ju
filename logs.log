2025-10-24 23:47:55,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-24 23:47:55,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-24 23:47:55,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-24 23:47:55,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-25 00:14:37,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-25 00:14:37,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-25 00:14:37,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-25 00:14:37,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:18:05,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:18:05,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:18:05,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:18:05,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:18:07,829:INFO:PyCaret ClassificationExperiment
2025-10-27 12:18:07,829:INFO:Logging name: clf-default-name
2025-10-27 12:18:07,829:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-27 12:18:07,829:INFO:version 3.3.2
2025-10-27 12:18:07,829:INFO:Initializing setup()
2025-10-27 12:18:07,829:INFO:self.USI: 1a33
2025-10-27 12:18:07,829:INFO:self._variable_keys: {'gpu_param', 'n_jobs_param', 'exp_id', 'X_train', '_available_plots', '_ml_usecase', 'log_plots_param', 'memory', 'y_test', 'html_param', 'idx', 'data', 'X_test', 'gpu_n_jobs_param', 'y_train', 'seed', 'y', 'X', 'fold_shuffle_param', 'fold_generator', 'target_param', 'is_multiclass', 'USI', 'fix_imbalance', 'logging_param', 'fold_groups_param', 'exp_name_log', 'pipeline'}
2025-10-27 12:18:07,829:INFO:Checking environment
2025-10-27 12:18:07,829:INFO:python_version: 3.10.4
2025-10-27 12:18:07,829:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-10-27 12:18:07,829:INFO:machine: AMD64
2025-10-27 12:18:07,829:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-27 12:18:07,829:INFO:Memory: svmem(total=8407076864, available=3028201472, percent=64.0, used=5378875392, free=3028201472)
2025-10-27 12:18:07,829:INFO:Physical Core: 6
2025-10-27 12:18:07,829:INFO:Logical Core: 12
2025-10-27 12:18:07,829:INFO:Checking libraries
2025-10-27 12:18:07,829:INFO:System:
2025-10-27 12:18:07,829:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-10-27 12:18:07,829:INFO:executable: C:\Users\Public\Documents\Adobe\Python\python.exe
2025-10-27 12:18:07,829:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-27 12:18:07,829:INFO:PyCaret required dependencies:
2025-10-27 12:18:07,968:INFO:                 pip: 25.2
2025-10-27 12:18:07,968:INFO:          setuptools: 58.1.0
2025-10-27 12:18:07,968:INFO:             pycaret: 3.3.2
2025-10-27 12:18:07,968:INFO:             IPython: 8.37.0
2025-10-27 12:18:07,968:INFO:          ipywidgets: 8.1.7
2025-10-27 12:18:07,968:INFO:                tqdm: 4.67.1
2025-10-27 12:18:07,968:INFO:               numpy: 1.26.4
2025-10-27 12:18:07,968:INFO:              pandas: 2.1.4
2025-10-27 12:18:07,968:INFO:              jinja2: 3.1.6
2025-10-27 12:18:07,968:INFO:               scipy: 1.11.4
2025-10-27 12:18:07,968:INFO:              joblib: 1.3.2
2025-10-27 12:18:07,968:INFO:             sklearn: 1.4.2
2025-10-27 12:18:07,968:INFO:                pyod: 2.0.5
2025-10-27 12:18:07,968:INFO:            imblearn: 0.14.0
2025-10-27 12:18:07,968:INFO:   category_encoders: 2.7.0
2025-10-27 12:18:07,968:INFO:            lightgbm: 4.6.0
2025-10-27 12:18:07,968:INFO:               numba: 0.62.1
2025-10-27 12:18:07,968:INFO:            requests: 2.32.5
2025-10-27 12:18:07,968:INFO:          matplotlib: 3.7.5
2025-10-27 12:18:07,968:INFO:          scikitplot: 0.3.7
2025-10-27 12:18:07,968:INFO:         yellowbrick: 1.5
2025-10-27 12:18:07,968:INFO:              plotly: 6.3.1
2025-10-27 12:18:07,968:INFO:    plotly-resampler: Not installed
2025-10-27 12:18:07,968:INFO:             kaleido: 1.1.0
2025-10-27 12:18:07,968:INFO:           schemdraw: 0.15
2025-10-27 12:18:07,968:INFO:         statsmodels: 0.14.5
2025-10-27 12:18:07,968:INFO:              sktime: 0.26.0
2025-10-27 12:18:07,968:INFO:               tbats: 1.1.3
2025-10-27 12:18:07,968:INFO:            pmdarima: 2.0.4
2025-10-27 12:18:07,968:INFO:              psutil: 7.1.1
2025-10-27 12:18:07,968:INFO:          markupsafe: 3.0.2
2025-10-27 12:18:07,968:INFO:             pickle5: Not installed
2025-10-27 12:18:07,968:INFO:         cloudpickle: 3.1.1
2025-10-27 12:18:07,968:INFO:         deprecation: 2.1.0
2025-10-27 12:18:07,968:INFO:              xxhash: 3.6.0
2025-10-27 12:18:07,968:INFO:           wurlitzer: Not installed
2025-10-27 12:18:07,968:INFO:PyCaret optional dependencies:
2025-10-27 12:18:08,120:INFO:                shap: Not installed
2025-10-27 12:18:08,120:INFO:           interpret: Not installed
2025-10-27 12:18:08,120:INFO:                umap: Not installed
2025-10-27 12:18:08,120:INFO:     ydata_profiling: Not installed
2025-10-27 12:18:08,120:INFO:  explainerdashboard: Not installed
2025-10-27 12:18:08,120:INFO:             autoviz: Not installed
2025-10-27 12:18:08,120:INFO:           fairlearn: Not installed
2025-10-27 12:18:08,120:INFO:          deepchecks: Not installed
2025-10-27 12:18:08,120:INFO:             xgboost: 3.1.1
2025-10-27 12:18:08,120:INFO:            catboost: Not installed
2025-10-27 12:18:08,120:INFO:              kmodes: Not installed
2025-10-27 12:18:08,120:INFO:             mlxtend: Not installed
2025-10-27 12:18:08,120:INFO:       statsforecast: Not installed
2025-10-27 12:18:08,120:INFO:        tune_sklearn: Not installed
2025-10-27 12:18:08,120:INFO:                 ray: Not installed
2025-10-27 12:18:08,120:INFO:            hyperopt: Not installed
2025-10-27 12:18:08,120:INFO:              optuna: Not installed
2025-10-27 12:18:08,120:INFO:               skopt: Not installed
2025-10-27 12:18:08,120:INFO:              mlflow: Not installed
2025-10-27 12:18:08,120:INFO:              gradio: Not installed
2025-10-27 12:18:08,120:INFO:             fastapi: Not installed
2025-10-27 12:18:08,120:INFO:             uvicorn: Not installed
2025-10-27 12:18:08,120:INFO:              m2cgen: Not installed
2025-10-27 12:18:08,120:INFO:           evidently: Not installed
2025-10-27 12:18:08,120:INFO:               fugue: Not installed
2025-10-27 12:18:08,120:INFO:           streamlit: 1.50.0
2025-10-27 12:18:08,120:INFO:             prophet: 1.2.1
2025-10-27 12:18:08,120:INFO:None
2025-10-27 12:18:08,120:INFO:Set up data.
2025-10-27 12:18:08,136:INFO:Set up folding strategy.
2025-10-27 12:18:08,136:INFO:Set up train/test split.
2025-10-27 12:18:08,152:INFO:Set up index.
2025-10-27 12:18:08,152:INFO:Assigning column types.
2025-10-27 12:18:08,167:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-27 12:18:08,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:18:08,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-27 12:18:08,230:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:18:08,267:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-27 12:18:08,287:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,289:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-27 12:18:08,320:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-27 12:18:08,336:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,367:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-27 12:18:08,382:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,382:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-27 12:18:08,445:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,521:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,537:INFO:Preparing preprocessing pipeline...
2025-10-27 12:18:08,537:INFO:Set up label encoding.
2025-10-27 12:18:08,537:INFO:Set up simple imputation.
2025-10-27 12:18:08,537:INFO:Set up encoding of categorical features.
2025-10-27 12:18:08,537:INFO:Set up column name cleaning.
2025-10-27 12:18:08,599:INFO:Finished creating preprocessing pipeline.
2025-10-27 12:18:08,599:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Year', 'AI Adoption Rate (%)',
                                             'AI-Generated Content Volume (TBs '
                                             'per year)',
                                             'Job Loss Due to AI (%)',
                                             'Revenue Incr...
                                    transformer=OneHotEncoder(cols=['Industry',
                                                                    'Top AI '
                                                                    'Tools '
                                                                    'Used',
                                                                    'Regulation '
                                                                    'Status'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-27 12:18:08,599:INFO:Creating final display dataframe.
2025-10-27 12:18:08,751:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                 42
1                        Target                                            Country
2                   Target type                                         Multiclass
3                Target mapping  Australia: 0, Canada: 1, China: 2, France: 3, ...
4           Original data shape                                          (200, 12)
5        Transformed data shape                                          (200, 29)
6   Transformed train set shape                                          (140, 29)
7    Transformed test set shape                                           (60, 29)
8              Numeric features                                                  8
9          Categorical features                                                  3
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               1a33
2025-10-27 12:18:08,814:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,875:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:18:08,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:18:08,878:INFO:setup() successfully completed in 1.05s...............
2025-10-27 12:18:08,879:INFO:Initializing compare_models()
2025-10-27 12:18:08,879:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-27 12:18:08,879:INFO:Checking exceptions
2025-10-27 12:18:08,881:INFO:Preparing display monitor
2025-10-27 12:18:08,884:INFO:Initializing Logistic Regression
2025-10-27 12:18:08,884:INFO:Total runtime is 0.0 minutes
2025-10-27 12:18:08,884:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:08,885:INFO:Initializing create_model()
2025-10-27 12:18:08,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:08,885:INFO:Checking exceptions
2025-10-27 12:18:08,885:INFO:Importing libraries
2025-10-27 12:18:08,885:INFO:Copying training dataset
2025-10-27 12:18:08,888:INFO:Defining folds
2025-10-27 12:18:08,888:INFO:Declaring metric variables
2025-10-27 12:18:08,888:INFO:Importing untrained model
2025-10-27 12:18:08,889:INFO:Logistic Regression Imported successfully
2025-10-27 12:18:08,889:INFO:Starting cross validation
2025-10-27 12:18:08,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:12,475:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,477:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,478:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,479:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,479:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,481:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,482:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,485:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,488:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,488:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,567:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,598:INFO:Calculating mean and std
2025-10-27 12:18:12,598:INFO:Creating metrics dataframe
2025-10-27 12:18:12,598:INFO:Uploading results into container
2025-10-27 12:18:12,598:INFO:Uploading model into container now
2025-10-27 12:18:12,598:INFO:_master_model_container: 1
2025-10-27 12:18:12,598:INFO:_display_container: 2
2025-10-27 12:18:12,598:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-27 12:18:12,598:INFO:create_model() successfully completed......................................
2025-10-27 12:18:12,847:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:12,847:INFO:Creating metrics dataframe
2025-10-27 12:18:12,847:INFO:Initializing K Neighbors Classifier
2025-10-27 12:18:12,847:INFO:Total runtime is 0.06605193217595419 minutes
2025-10-27 12:18:12,847:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:12,847:INFO:Initializing create_model()
2025-10-27 12:18:12,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:12,847:INFO:Checking exceptions
2025-10-27 12:18:12,847:INFO:Importing libraries
2025-10-27 12:18:12,847:INFO:Copying training dataset
2025-10-27 12:18:12,857:INFO:Defining folds
2025-10-27 12:18:12,857:INFO:Declaring metric variables
2025-10-27 12:18:12,857:INFO:Importing untrained model
2025-10-27 12:18:12,857:INFO:K Neighbors Classifier Imported successfully
2025-10-27 12:18:12,857:INFO:Starting cross validation
2025-10-27 12:18:12,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:12,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,599:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,614:INFO:Calculating mean and std
2025-10-27 12:18:14,614:INFO:Creating metrics dataframe
2025-10-27 12:18:14,614:INFO:Uploading results into container
2025-10-27 12:18:14,614:INFO:Uploading model into container now
2025-10-27 12:18:14,614:INFO:_master_model_container: 2
2025-10-27 12:18:14,614:INFO:_display_container: 2
2025-10-27 12:18:14,614:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-27 12:18:14,614:INFO:create_model() successfully completed......................................
2025-10-27 12:18:14,718:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:14,718:INFO:Creating metrics dataframe
2025-10-27 12:18:14,718:INFO:Initializing Naive Bayes
2025-10-27 12:18:14,718:INFO:Total runtime is 0.09723676045735677 minutes
2025-10-27 12:18:14,718:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:14,718:INFO:Initializing create_model()
2025-10-27 12:18:14,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:14,718:INFO:Checking exceptions
2025-10-27 12:18:14,718:INFO:Importing libraries
2025-10-27 12:18:14,718:INFO:Copying training dataset
2025-10-27 12:18:14,718:INFO:Defining folds
2025-10-27 12:18:14,718:INFO:Declaring metric variables
2025-10-27 12:18:14,718:INFO:Importing untrained model
2025-10-27 12:18:14,718:INFO:Naive Bayes Imported successfully
2025-10-27 12:18:14,718:INFO:Starting cross validation
2025-10-27 12:18:14,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,828:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,843:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,859:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,860:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:14,861:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:14,876:INFO:Calculating mean and std
2025-10-27 12:18:14,877:INFO:Creating metrics dataframe
2025-10-27 12:18:14,878:INFO:Uploading results into container
2025-10-27 12:18:14,878:INFO:Uploading model into container now
2025-10-27 12:18:14,878:INFO:_master_model_container: 3
2025-10-27 12:18:14,878:INFO:_display_container: 2
2025-10-27 12:18:14,879:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-27 12:18:14,879:INFO:create_model() successfully completed......................................
2025-10-27 12:18:14,937:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:14,937:INFO:Creating metrics dataframe
2025-10-27 12:18:14,937:INFO:Initializing Decision Tree Classifier
2025-10-27 12:18:14,937:INFO:Total runtime is 0.10087383190790812 minutes
2025-10-27 12:18:14,937:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:14,937:INFO:Initializing create_model()
2025-10-27 12:18:14,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:14,937:INFO:Checking exceptions
2025-10-27 12:18:14,937:INFO:Importing libraries
2025-10-27 12:18:14,937:INFO:Copying training dataset
2025-10-27 12:18:14,952:INFO:Defining folds
2025-10-27 12:18:14,952:INFO:Declaring metric variables
2025-10-27 12:18:14,952:INFO:Importing untrained model
2025-10-27 12:18:14,952:INFO:Decision Tree Classifier Imported successfully
2025-10-27 12:18:14,952:INFO:Starting cross validation
2025-10-27 12:18:14,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:15,055:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,055:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,058:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,058:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,060:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,060:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,062:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,062:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,068:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,070:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,070:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,071:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,071:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,073:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,073:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,073:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,073:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,073:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,074:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,074:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,074:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,076:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,076:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,076:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,076:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,076:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,077:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,077:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,077:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,078:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,078:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,078:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,079:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,079:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,079:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,080:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,081:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,081:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,081:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,082:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,086:INFO:Calculating mean and std
2025-10-27 12:18:15,086:INFO:Creating metrics dataframe
2025-10-27 12:18:15,088:INFO:Uploading results into container
2025-10-27 12:18:15,088:INFO:Uploading model into container now
2025-10-27 12:18:15,088:INFO:_master_model_container: 4
2025-10-27 12:18:15,088:INFO:_display_container: 2
2025-10-27 12:18:15,088:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-27 12:18:15,088:INFO:create_model() successfully completed......................................
2025-10-27 12:18:15,151:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:15,151:INFO:Creating metrics dataframe
2025-10-27 12:18:15,151:INFO:Initializing SVM - Linear Kernel
2025-10-27 12:18:15,151:INFO:Total runtime is 0.10444550116856893 minutes
2025-10-27 12:18:15,151:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:15,151:INFO:Initializing create_model()
2025-10-27 12:18:15,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:15,151:INFO:Checking exceptions
2025-10-27 12:18:15,151:INFO:Importing libraries
2025-10-27 12:18:15,151:INFO:Copying training dataset
2025-10-27 12:18:15,151:INFO:Defining folds
2025-10-27 12:18:15,151:INFO:Declaring metric variables
2025-10-27 12:18:15,151:INFO:Importing untrained model
2025-10-27 12:18:15,151:INFO:SVM - Linear Kernel Imported successfully
2025-10-27 12:18:15,151:INFO:Starting cross validation
2025-10-27 12:18:15,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:15,305:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,305:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,305:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,305:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,321:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,336:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,352:INFO:Calculating mean and std
2025-10-27 12:18:15,352:INFO:Creating metrics dataframe
2025-10-27 12:18:15,352:INFO:Uploading results into container
2025-10-27 12:18:15,352:INFO:Uploading model into container now
2025-10-27 12:18:15,352:INFO:_master_model_container: 5
2025-10-27 12:18:15,352:INFO:_display_container: 2
2025-10-27 12:18:15,352:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-27 12:18:15,352:INFO:create_model() successfully completed......................................
2025-10-27 12:18:15,414:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:15,414:INFO:Creating metrics dataframe
2025-10-27 12:18:15,414:INFO:Initializing Ridge Classifier
2025-10-27 12:18:15,414:INFO:Total runtime is 0.10883720715840658 minutes
2025-10-27 12:18:15,414:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:15,414:INFO:Initializing create_model()
2025-10-27 12:18:15,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:15,414:INFO:Checking exceptions
2025-10-27 12:18:15,414:INFO:Importing libraries
2025-10-27 12:18:15,414:INFO:Copying training dataset
2025-10-27 12:18:15,414:INFO:Defining folds
2025-10-27 12:18:15,414:INFO:Declaring metric variables
2025-10-27 12:18:15,414:INFO:Importing untrained model
2025-10-27 12:18:15,414:INFO:Ridge Classifier Imported successfully
2025-10-27 12:18:15,414:INFO:Starting cross validation
2025-10-27 12:18:15,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,567:INFO:Calculating mean and std
2025-10-27 12:18:15,567:INFO:Creating metrics dataframe
2025-10-27 12:18:15,567:INFO:Uploading results into container
2025-10-27 12:18:15,567:INFO:Uploading model into container now
2025-10-27 12:18:15,567:INFO:_master_model_container: 6
2025-10-27 12:18:15,567:INFO:_display_container: 2
2025-10-27 12:18:15,567:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-27 12:18:15,567:INFO:create_model() successfully completed......................................
2025-10-27 12:18:15,630:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:15,630:INFO:Creating metrics dataframe
2025-10-27 12:18:15,630:INFO:Initializing Random Forest Classifier
2025-10-27 12:18:15,630:INFO:Total runtime is 0.11242076953252157 minutes
2025-10-27 12:18:15,630:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:15,630:INFO:Initializing create_model()
2025-10-27 12:18:15,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:15,630:INFO:Checking exceptions
2025-10-27 12:18:15,630:INFO:Importing libraries
2025-10-27 12:18:15,630:INFO:Copying training dataset
2025-10-27 12:18:15,630:INFO:Defining folds
2025-10-27 12:18:15,630:INFO:Declaring metric variables
2025-10-27 12:18:15,630:INFO:Importing untrained model
2025-10-27 12:18:15,630:INFO:Random Forest Classifier Imported successfully
2025-10-27 12:18:15,630:INFO:Starting cross validation
2025-10-27 12:18:15,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:15,935:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,935:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:15,998:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,014:INFO:Calculating mean and std
2025-10-27 12:18:16,014:INFO:Creating metrics dataframe
2025-10-27 12:18:16,014:INFO:Uploading results into container
2025-10-27 12:18:16,014:INFO:Uploading model into container now
2025-10-27 12:18:16,014:INFO:_master_model_container: 7
2025-10-27 12:18:16,014:INFO:_display_container: 2
2025-10-27 12:18:16,014:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-27 12:18:16,014:INFO:create_model() successfully completed......................................
2025-10-27 12:18:16,090:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:16,090:INFO:Creating metrics dataframe
2025-10-27 12:18:16,092:INFO:Initializing Quadratic Discriminant Analysis
2025-10-27 12:18:16,092:INFO:Total runtime is 0.12013567288716635 minutes
2025-10-27 12:18:16,092:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:16,092:INFO:Initializing create_model()
2025-10-27 12:18:16,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:16,093:INFO:Checking exceptions
2025-10-27 12:18:16,093:INFO:Importing libraries
2025-10-27 12:18:16,093:INFO:Copying training dataset
2025-10-27 12:18:16,095:INFO:Defining folds
2025-10-27 12:18:16,095:INFO:Declaring metric variables
2025-10-27 12:18:16,095:INFO:Importing untrained model
2025-10-27 12:18:16,095:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-27 12:18:16,095:INFO:Starting cross validation
2025-10-27 12:18:16,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,184:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,199:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,215:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,230:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,230:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,230:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,246:INFO:Calculating mean and std
2025-10-27 12:18:16,247:INFO:Creating metrics dataframe
2025-10-27 12:18:16,248:INFO:Uploading results into container
2025-10-27 12:18:16,248:INFO:Uploading model into container now
2025-10-27 12:18:16,248:INFO:_master_model_container: 8
2025-10-27 12:18:16,248:INFO:_display_container: 2
2025-10-27 12:18:16,248:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-27 12:18:16,248:INFO:create_model() successfully completed......................................
2025-10-27 12:18:16,320:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:16,320:INFO:Creating metrics dataframe
2025-10-27 12:18:16,320:INFO:Initializing Ada Boost Classifier
2025-10-27 12:18:16,320:INFO:Total runtime is 0.12392734289169313 minutes
2025-10-27 12:18:16,320:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:16,320:INFO:Initializing create_model()
2025-10-27 12:18:16,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:16,320:INFO:Checking exceptions
2025-10-27 12:18:16,320:INFO:Importing libraries
2025-10-27 12:18:16,320:INFO:Copying training dataset
2025-10-27 12:18:16,320:INFO:Defining folds
2025-10-27 12:18:16,320:INFO:Declaring metric variables
2025-10-27 12:18:16,336:INFO:Importing untrained model
2025-10-27 12:18:16,336:INFO:Ada Boost Classifier Imported successfully
2025-10-27 12:18:16,336:INFO:Starting cross validation
2025-10-27 12:18:16,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,414:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,521:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,536:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,552:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:16,568:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:16,583:INFO:Calculating mean and std
2025-10-27 12:18:16,583:INFO:Creating metrics dataframe
2025-10-27 12:18:16,583:INFO:Uploading results into container
2025-10-27 12:18:16,583:INFO:Uploading model into container now
2025-10-27 12:18:16,583:INFO:_master_model_container: 9
2025-10-27 12:18:16,583:INFO:_display_container: 2
2025-10-27 12:18:16,583:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-27 12:18:16,583:INFO:create_model() successfully completed......................................
2025-10-27 12:18:16,658:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:16,658:INFO:Creating metrics dataframe
2025-10-27 12:18:16,660:INFO:Initializing Gradient Boosting Classifier
2025-10-27 12:18:16,660:INFO:Total runtime is 0.1295904596646627 minutes
2025-10-27 12:18:16,660:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:16,660:INFO:Initializing create_model()
2025-10-27 12:18:16,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:16,660:INFO:Checking exceptions
2025-10-27 12:18:16,660:INFO:Importing libraries
2025-10-27 12:18:16,660:INFO:Copying training dataset
2025-10-27 12:18:16,663:INFO:Defining folds
2025-10-27 12:18:16,663:INFO:Declaring metric variables
2025-10-27 12:18:16,663:INFO:Importing untrained model
2025-10-27 12:18:16,663:INFO:Gradient Boosting Classifier Imported successfully
2025-10-27 12:18:16,663:INFO:Starting cross validation
2025-10-27 12:18:16,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,785:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,801:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,801:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,801:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,801:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,801:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,801:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,816:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,816:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,816:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,816:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,816:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,832:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,904:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:17,904:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,920:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,920:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:17,920:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:17,936:INFO:Calculating mean and std
2025-10-27 12:18:17,936:INFO:Creating metrics dataframe
2025-10-27 12:18:17,936:INFO:Uploading results into container
2025-10-27 12:18:17,936:INFO:Uploading model into container now
2025-10-27 12:18:17,936:INFO:_master_model_container: 10
2025-10-27 12:18:17,936:INFO:_display_container: 2
2025-10-27 12:18:17,936:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-27 12:18:17,936:INFO:create_model() successfully completed......................................
2025-10-27 12:18:18,014:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:18,014:INFO:Creating metrics dataframe
2025-10-27 12:18:18,014:INFO:Initializing Linear Discriminant Analysis
2025-10-27 12:18:18,014:INFO:Total runtime is 0.15215684175491334 minutes
2025-10-27 12:18:18,014:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:18,014:INFO:Initializing create_model()
2025-10-27 12:18:18,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:18,014:INFO:Checking exceptions
2025-10-27 12:18:18,014:INFO:Importing libraries
2025-10-27 12:18:18,014:INFO:Copying training dataset
2025-10-27 12:18:18,014:INFO:Defining folds
2025-10-27 12:18:18,014:INFO:Declaring metric variables
2025-10-27 12:18:18,014:INFO:Importing untrained model
2025-10-27 12:18:18,014:INFO:Linear Discriminant Analysis Imported successfully
2025-10-27 12:18:18,014:INFO:Starting cross validation
2025-10-27 12:18:18,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:18,105:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,105:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,105:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,167:INFO:Calculating mean and std
2025-10-27 12:18:18,167:INFO:Creating metrics dataframe
2025-10-27 12:18:18,167:INFO:Uploading results into container
2025-10-27 12:18:18,167:INFO:Uploading model into container now
2025-10-27 12:18:18,167:INFO:_master_model_container: 11
2025-10-27 12:18:18,167:INFO:_display_container: 2
2025-10-27 12:18:18,167:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-27 12:18:18,167:INFO:create_model() successfully completed......................................
2025-10-27 12:18:18,230:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:18,230:INFO:Creating metrics dataframe
2025-10-27 12:18:18,230:INFO:Initializing Extra Trees Classifier
2025-10-27 12:18:18,230:INFO:Total runtime is 0.15575757026672366 minutes
2025-10-27 12:18:18,230:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:18,230:INFO:Initializing create_model()
2025-10-27 12:18:18,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:18,230:INFO:Checking exceptions
2025-10-27 12:18:18,230:INFO:Importing libraries
2025-10-27 12:18:18,230:INFO:Copying training dataset
2025-10-27 12:18:18,230:INFO:Defining folds
2025-10-27 12:18:18,230:INFO:Declaring metric variables
2025-10-27 12:18:18,230:INFO:Importing untrained model
2025-10-27 12:18:18,230:INFO:Extra Trees Classifier Imported successfully
2025-10-27 12:18:18,230:INFO:Starting cross validation
2025-10-27 12:18:18,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:18,504:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,504:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,504:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,504:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,504:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,520:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,535:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,551:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,567:INFO:Calculating mean and std
2025-10-27 12:18:18,567:INFO:Creating metrics dataframe
2025-10-27 12:18:18,567:INFO:Uploading results into container
2025-10-27 12:18:18,567:INFO:Uploading model into container now
2025-10-27 12:18:18,567:INFO:_master_model_container: 12
2025-10-27 12:18:18,567:INFO:_display_container: 2
2025-10-27 12:18:18,567:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-27 12:18:18,567:INFO:create_model() successfully completed......................................
2025-10-27 12:18:18,629:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:18,629:INFO:Creating metrics dataframe
2025-10-27 12:18:18,629:INFO:Initializing Extreme Gradient Boosting
2025-10-27 12:18:18,629:INFO:Total runtime is 0.16241621573766074 minutes
2025-10-27 12:18:18,629:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:18,629:INFO:Initializing create_model()
2025-10-27 12:18:18,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:18,629:INFO:Checking exceptions
2025-10-27 12:18:18,629:INFO:Importing libraries
2025-10-27 12:18:18,629:INFO:Copying training dataset
2025-10-27 12:18:18,629:INFO:Defining folds
2025-10-27 12:18:18,629:INFO:Declaring metric variables
2025-10-27 12:18:18,629:INFO:Importing untrained model
2025-10-27 12:18:18,629:INFO:Extreme Gradient Boosting Imported successfully
2025-10-27 12:18:18,629:INFO:Starting cross validation
2025-10-27 12:18:18,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:18,935:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,935:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,935:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,935:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,951:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,967:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:18,982:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:18,998:INFO:Calculating mean and std
2025-10-27 12:18:18,998:INFO:Creating metrics dataframe
2025-10-27 12:18:18,998:INFO:Uploading results into container
2025-10-27 12:18:18,998:INFO:Uploading model into container now
2025-10-27 12:18:18,998:INFO:_master_model_container: 13
2025-10-27 12:18:18,998:INFO:_display_container: 2
2025-10-27 12:18:18,998:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-10-27 12:18:18,998:INFO:create_model() successfully completed......................................
2025-10-27 12:18:19,074:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:19,074:INFO:Creating metrics dataframe
2025-10-27 12:18:19,076:INFO:Initializing Light Gradient Boosting Machine
2025-10-27 12:18:19,076:INFO:Total runtime is 0.1698679526646932 minutes
2025-10-27 12:18:19,076:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:19,076:INFO:Initializing create_model()
2025-10-27 12:18:19,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:19,076:INFO:Checking exceptions
2025-10-27 12:18:19,076:INFO:Importing libraries
2025-10-27 12:18:19,076:INFO:Copying training dataset
2025-10-27 12:18:19,079:INFO:Defining folds
2025-10-27 12:18:19,079:INFO:Declaring metric variables
2025-10-27 12:18:19,079:INFO:Importing untrained model
2025-10-27 12:18:19,079:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-27 12:18:19,079:INFO:Starting cross validation
2025-10-27 12:18:19,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:21,689:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,689:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,704:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,704:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,751:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,767:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,767:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,767:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,767:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,767:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,798:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,798:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,798:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,798:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,829:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,829:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,829:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,829:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,847:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,847:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,847:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,882:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,884:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,885:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,887:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,888:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:21,889:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,904:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,904:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,904:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:21,936:INFO:Calculating mean and std
2025-10-27 12:18:21,936:INFO:Creating metrics dataframe
2025-10-27 12:18:21,936:INFO:Uploading results into container
2025-10-27 12:18:21,936:INFO:Uploading model into container now
2025-10-27 12:18:21,936:INFO:_master_model_container: 14
2025-10-27 12:18:21,936:INFO:_display_container: 2
2025-10-27 12:18:21,936:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-27 12:18:21,936:INFO:create_model() successfully completed......................................
2025-10-27 12:18:22,014:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:22,014:INFO:Creating metrics dataframe
2025-10-27 12:18:22,014:INFO:Initializing Dummy Classifier
2025-10-27 12:18:22,014:INFO:Total runtime is 0.21882621049880982 minutes
2025-10-27 12:18:22,014:INFO:SubProcess create_model() called ==================================
2025-10-27 12:18:22,014:INFO:Initializing create_model()
2025-10-27 12:18:22,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002651EE36B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:22,014:INFO:Checking exceptions
2025-10-27 12:18:22,014:INFO:Importing libraries
2025-10-27 12:18:22,014:INFO:Copying training dataset
2025-10-27 12:18:22,014:INFO:Defining folds
2025-10-27 12:18:22,014:INFO:Declaring metric variables
2025-10-27 12:18:22,014:INFO:Importing untrained model
2025-10-27 12:18:22,014:INFO:Dummy Classifier Imported successfully
2025-10-27 12:18:22,029:INFO:Starting cross validation
2025-10-27 12:18:22,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,120:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,136:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,151:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,151:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,151:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,151:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-27 12:18:22,151:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'USA') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-10-27 12:18:22,167:INFO:Calculating mean and std
2025-10-27 12:18:22,167:INFO:Creating metrics dataframe
2025-10-27 12:18:22,167:INFO:Uploading results into container
2025-10-27 12:18:22,167:INFO:Uploading model into container now
2025-10-27 12:18:22,167:INFO:_master_model_container: 15
2025-10-27 12:18:22,167:INFO:_display_container: 2
2025-10-27 12:18:22,167:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-27 12:18:22,167:INFO:create_model() successfully completed......................................
2025-10-27 12:18:22,229:INFO:SubProcess create_model() end ==================================
2025-10-27 12:18:22,229:INFO:Creating metrics dataframe
2025-10-27 12:18:22,229:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-10-27 12:18:22,229:INFO:Initializing create_model()
2025-10-27 12:18:22,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002651DF952D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:18:22,229:INFO:Checking exceptions
2025-10-27 12:18:22,229:INFO:Importing libraries
2025-10-27 12:18:22,229:INFO:Copying training dataset
2025-10-27 12:18:22,229:INFO:Defining folds
2025-10-27 12:18:22,229:INFO:Declaring metric variables
2025-10-27 12:18:22,229:INFO:Importing untrained model
2025-10-27 12:18:22,229:INFO:Declaring custom model
2025-10-27 12:18:22,229:INFO:Ridge Classifier Imported successfully
2025-10-27 12:18:22,245:INFO:Cross validation set to False
2025-10-27 12:18:22,245:INFO:Fitting Model
2025-10-27 12:18:22,279:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-27 12:18:22,279:INFO:create_model() successfully completed......................................
2025-10-27 12:18:22,352:INFO:_master_model_container: 15
2025-10-27 12:18:22,352:INFO:_display_container: 2
2025-10-27 12:18:22,352:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-27 12:18:22,352:INFO:compare_models() successfully completed......................................
2025-10-27 12:39:14,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:39:14,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:39:14,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:39:14,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-27 12:39:16,795:INFO:PyCaret RegressionExperiment
2025-10-27 12:39:16,795:INFO:Logging name: reg-default-name
2025-10-27 12:39:16,795:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-27 12:39:16,795:INFO:version 3.3.2
2025-10-27 12:39:16,795:INFO:Initializing setup()
2025-10-27 12:39:16,795:INFO:self.USI: 2814
2025-10-27 12:39:16,795:INFO:self._variable_keys: {'USI', 'logging_param', 'gpu_param', 'pipeline', 'y_train', 'exp_id', 'gpu_n_jobs_param', 'fold_groups_param', '_available_plots', 'X_test', 'X', 'log_plots_param', 'X_train', 'memory', 'fold_generator', 'target_param', '_ml_usecase', 'y_test', 'exp_name_log', 'seed', 'data', 'html_param', 'idx', 'n_jobs_param', 'y', 'fold_shuffle_param', 'transform_target_param'}
2025-10-27 12:39:16,795:INFO:Checking environment
2025-10-27 12:39:16,796:INFO:python_version: 3.10.4
2025-10-27 12:39:16,796:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-10-27 12:39:16,796:INFO:machine: AMD64
2025-10-27 12:39:16,796:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-27 12:39:16,800:INFO:Memory: svmem(total=8407076864, available=1578442752, percent=81.2, used=6828634112, free=1578442752)
2025-10-27 12:39:16,800:INFO:Physical Core: 6
2025-10-27 12:39:16,800:INFO:Logical Core: 12
2025-10-27 12:39:16,800:INFO:Checking libraries
2025-10-27 12:39:16,800:INFO:System:
2025-10-27 12:39:16,800:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-10-27 12:39:16,800:INFO:executable: C:\Users\Public\Documents\Adobe\Python\python.exe
2025-10-27 12:39:16,801:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-27 12:39:16,801:INFO:PyCaret required dependencies:
2025-10-27 12:39:16,874:INFO:                 pip: 25.2
2025-10-27 12:39:16,875:INFO:          setuptools: 58.1.0
2025-10-27 12:39:16,875:INFO:             pycaret: 3.3.2
2025-10-27 12:39:16,875:INFO:             IPython: 8.37.0
2025-10-27 12:39:16,875:INFO:          ipywidgets: 8.1.7
2025-10-27 12:39:16,875:INFO:                tqdm: 4.67.1
2025-10-27 12:39:16,875:INFO:               numpy: 1.26.4
2025-10-27 12:39:16,876:INFO:              pandas: 2.1.4
2025-10-27 12:39:16,876:INFO:              jinja2: 3.1.6
2025-10-27 12:39:16,876:INFO:               scipy: 1.11.4
2025-10-27 12:39:16,876:INFO:              joblib: 1.3.2
2025-10-27 12:39:16,876:INFO:             sklearn: 1.4.2
2025-10-27 12:39:16,876:INFO:                pyod: 2.0.5
2025-10-27 12:39:16,876:INFO:            imblearn: 0.14.0
2025-10-27 12:39:16,876:INFO:   category_encoders: 2.7.0
2025-10-27 12:39:16,876:INFO:            lightgbm: 4.6.0
2025-10-27 12:39:16,876:INFO:               numba: 0.62.1
2025-10-27 12:39:16,876:INFO:            requests: 2.32.5
2025-10-27 12:39:16,876:INFO:          matplotlib: 3.7.5
2025-10-27 12:39:16,877:INFO:          scikitplot: 0.3.7
2025-10-27 12:39:16,877:INFO:         yellowbrick: 1.5
2025-10-27 12:39:16,877:INFO:              plotly: 6.3.1
2025-10-27 12:39:16,877:INFO:    plotly-resampler: Not installed
2025-10-27 12:39:16,877:INFO:             kaleido: 1.1.0
2025-10-27 12:39:16,877:INFO:           schemdraw: 0.15
2025-10-27 12:39:16,877:INFO:         statsmodels: 0.14.5
2025-10-27 12:39:16,877:INFO:              sktime: 0.26.0
2025-10-27 12:39:16,877:INFO:               tbats: 1.1.3
2025-10-27 12:39:16,877:INFO:            pmdarima: 2.0.4
2025-10-27 12:39:16,877:INFO:              psutil: 7.1.1
2025-10-27 12:39:16,877:INFO:          markupsafe: 3.0.2
2025-10-27 12:39:16,877:INFO:             pickle5: Not installed
2025-10-27 12:39:16,877:INFO:         cloudpickle: 3.1.1
2025-10-27 12:39:16,877:INFO:         deprecation: 2.1.0
2025-10-27 12:39:16,877:INFO:              xxhash: 3.6.0
2025-10-27 12:39:16,877:INFO:           wurlitzer: Not installed
2025-10-27 12:39:16,877:INFO:PyCaret optional dependencies:
2025-10-27 12:39:16,948:INFO:                shap: Not installed
2025-10-27 12:39:16,948:INFO:           interpret: Not installed
2025-10-27 12:39:16,948:INFO:                umap: Not installed
2025-10-27 12:39:16,948:INFO:     ydata_profiling: Not installed
2025-10-27 12:39:16,948:INFO:  explainerdashboard: Not installed
2025-10-27 12:39:16,948:INFO:             autoviz: Not installed
2025-10-27 12:39:16,948:INFO:           fairlearn: Not installed
2025-10-27 12:39:16,948:INFO:          deepchecks: Not installed
2025-10-27 12:39:16,948:INFO:             xgboost: 3.1.1
2025-10-27 12:39:16,948:INFO:            catboost: Not installed
2025-10-27 12:39:16,948:INFO:              kmodes: Not installed
2025-10-27 12:39:16,948:INFO:             mlxtend: Not installed
2025-10-27 12:39:16,948:INFO:       statsforecast: Not installed
2025-10-27 12:39:16,948:INFO:        tune_sklearn: Not installed
2025-10-27 12:39:16,948:INFO:                 ray: Not installed
2025-10-27 12:39:16,948:INFO:            hyperopt: Not installed
2025-10-27 12:39:16,948:INFO:              optuna: Not installed
2025-10-27 12:39:16,948:INFO:               skopt: Not installed
2025-10-27 12:39:16,948:INFO:              mlflow: Not installed
2025-10-27 12:39:16,948:INFO:              gradio: Not installed
2025-10-27 12:39:16,948:INFO:             fastapi: Not installed
2025-10-27 12:39:16,948:INFO:             uvicorn: Not installed
2025-10-27 12:39:16,948:INFO:              m2cgen: Not installed
2025-10-27 12:39:16,948:INFO:           evidently: Not installed
2025-10-27 12:39:16,948:INFO:               fugue: Not installed
2025-10-27 12:39:16,948:INFO:           streamlit: 1.50.0
2025-10-27 12:39:16,948:INFO:             prophet: 1.2.1
2025-10-27 12:39:16,948:INFO:None
2025-10-27 12:39:16,948:INFO:Set up data.
2025-10-27 12:39:16,964:INFO:Set up folding strategy.
2025-10-27 12:39:16,964:INFO:Set up train/test split.
2025-10-27 12:39:16,985:INFO:Set up index.
2025-10-27 12:39:16,986:INFO:Assigning column types.
2025-10-27 12:39:17,015:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-27 12:39:17,015:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,020:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,136:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:17,139:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,306:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,308:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:17,314:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-27 12:39:17,320:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,459:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:17,465:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,599:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:17,603:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-27 12:39:17,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,730:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,730:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:17,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,861:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:17,864:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-27 12:39:17,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:17,992:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:17,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:18,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:18,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-27 12:39:18,113:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:18,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:18,116:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-27 12:39:18,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:18,246:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:18,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:18,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-27 12:39:18,369:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:18,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:18,372:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-27 12:39:18,502:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:18,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:18,644:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:18,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:18,649:INFO:Preparing preprocessing pipeline...
2025-10-27 12:39:18,649:INFO:Set up simple imputation.
2025-10-27 12:39:18,652:INFO:Set up column name cleaning.
2025-10-27 12:39:18,818:INFO:Finished creating preprocessing pipeline.
2025-10-27 12:39:18,822:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'Years of Experience'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-27 12:39:18,823:INFO:Creating final display dataframe.
2025-10-27 12:39:19,188:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target     yearly salary
2                   Target type        Regression
3           Original data shape       (1761, 204)
4        Transformed data shape       (1761, 204)
5   Transformed train set shape       (1232, 204)
6    Transformed test set shape        (529, 204)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2814
2025-10-27 12:39:19,330:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:19,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:19,453:INFO:Soft dependency imported: xgboost: 3.1.1
2025-10-27 12:39:19,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-27 12:39:19,455:INFO:setup() successfully completed in 2.67s...............
2025-10-27 12:39:19,455:INFO:Initializing compare_models()
2025-10-27 12:39:19,455:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-10-27 12:39:19,455:INFO:Checking exceptions
2025-10-27 12:39:19,467:INFO:Preparing display monitor
2025-10-27 12:39:19,471:INFO:Initializing Linear Regression
2025-10-27 12:39:19,471:INFO:Total runtime is 0.0 minutes
2025-10-27 12:39:19,471:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:19,472:INFO:Initializing create_model()
2025-10-27 12:39:19,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:19,472:INFO:Checking exceptions
2025-10-27 12:39:19,472:INFO:Importing libraries
2025-10-27 12:39:19,472:INFO:Copying training dataset
2025-10-27 12:39:19,500:INFO:Defining folds
2025-10-27 12:39:19,500:INFO:Declaring metric variables
2025-10-27 12:39:19,501:INFO:Importing untrained model
2025-10-27 12:39:19,501:INFO:Linear Regression Imported successfully
2025-10-27 12:39:19,501:INFO:Starting cross validation
2025-10-27 12:39:19,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:26,263:INFO:Calculating mean and std
2025-10-27 12:39:26,267:INFO:Creating metrics dataframe
2025-10-27 12:39:26,274:INFO:Uploading results into container
2025-10-27 12:39:26,277:INFO:Uploading model into container now
2025-10-27 12:39:26,279:INFO:_master_model_container: 1
2025-10-27 12:39:26,279:INFO:_display_container: 2
2025-10-27 12:39:26,280:INFO:LinearRegression(n_jobs=-1)
2025-10-27 12:39:26,280:INFO:create_model() successfully completed......................................
2025-10-27 12:39:26,688:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:26,688:INFO:Creating metrics dataframe
2025-10-27 12:39:26,690:INFO:Initializing Lasso Regression
2025-10-27 12:39:26,690:INFO:Total runtime is 0.1203182021776835 minutes
2025-10-27 12:39:26,690:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:26,690:INFO:Initializing create_model()
2025-10-27 12:39:26,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:26,690:INFO:Checking exceptions
2025-10-27 12:39:26,690:INFO:Importing libraries
2025-10-27 12:39:26,690:INFO:Copying training dataset
2025-10-27 12:39:26,720:INFO:Defining folds
2025-10-27 12:39:26,721:INFO:Declaring metric variables
2025-10-27 12:39:26,721:INFO:Importing untrained model
2025-10-27 12:39:26,721:INFO:Lasso Regression Imported successfully
2025-10-27 12:39:26,721:INFO:Starting cross validation
2025-10-27 12:39:26,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:29,232:INFO:Calculating mean and std
2025-10-27 12:39:29,233:INFO:Creating metrics dataframe
2025-10-27 12:39:29,235:INFO:Uploading results into container
2025-10-27 12:39:29,236:INFO:Uploading model into container now
2025-10-27 12:39:29,236:INFO:_master_model_container: 2
2025-10-27 12:39:29,236:INFO:_display_container: 2
2025-10-27 12:39:29,236:INFO:Lasso(random_state=42)
2025-10-27 12:39:29,236:INFO:create_model() successfully completed......................................
2025-10-27 12:39:29,406:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:29,406:INFO:Creating metrics dataframe
2025-10-27 12:39:29,413:INFO:Initializing Ridge Regression
2025-10-27 12:39:29,413:INFO:Total runtime is 0.16570159196853637 minutes
2025-10-27 12:39:29,413:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:29,414:INFO:Initializing create_model()
2025-10-27 12:39:29,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:29,414:INFO:Checking exceptions
2025-10-27 12:39:29,414:INFO:Importing libraries
2025-10-27 12:39:29,414:INFO:Copying training dataset
2025-10-27 12:39:29,443:INFO:Defining folds
2025-10-27 12:39:29,443:INFO:Declaring metric variables
2025-10-27 12:39:29,443:INFO:Importing untrained model
2025-10-27 12:39:29,444:INFO:Ridge Regression Imported successfully
2025-10-27 12:39:29,444:INFO:Starting cross validation
2025-10-27 12:39:29,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:29,659:INFO:Calculating mean and std
2025-10-27 12:39:29,660:INFO:Creating metrics dataframe
2025-10-27 12:39:29,663:INFO:Uploading results into container
2025-10-27 12:39:29,664:INFO:Uploading model into container now
2025-10-27 12:39:29,665:INFO:_master_model_container: 3
2025-10-27 12:39:29,665:INFO:_display_container: 2
2025-10-27 12:39:29,665:INFO:Ridge(random_state=42)
2025-10-27 12:39:29,665:INFO:create_model() successfully completed......................................
2025-10-27 12:39:29,795:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:29,795:INFO:Creating metrics dataframe
2025-10-27 12:39:29,798:INFO:Initializing Elastic Net
2025-10-27 12:39:29,799:INFO:Total runtime is 0.17213489214579264 minutes
2025-10-27 12:39:29,799:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:29,799:INFO:Initializing create_model()
2025-10-27 12:39:29,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:29,799:INFO:Checking exceptions
2025-10-27 12:39:29,799:INFO:Importing libraries
2025-10-27 12:39:29,799:INFO:Copying training dataset
2025-10-27 12:39:29,836:INFO:Defining folds
2025-10-27 12:39:29,836:INFO:Declaring metric variables
2025-10-27 12:39:29,836:INFO:Importing untrained model
2025-10-27 12:39:29,837:INFO:Elastic Net Imported successfully
2025-10-27 12:39:29,837:INFO:Starting cross validation
2025-10-27 12:39:29,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:30,070:INFO:Calculating mean and std
2025-10-27 12:39:30,071:INFO:Creating metrics dataframe
2025-10-27 12:39:30,072:INFO:Uploading results into container
2025-10-27 12:39:30,073:INFO:Uploading model into container now
2025-10-27 12:39:30,073:INFO:_master_model_container: 4
2025-10-27 12:39:30,073:INFO:_display_container: 2
2025-10-27 12:39:30,073:INFO:ElasticNet(random_state=42)
2025-10-27 12:39:30,073:INFO:create_model() successfully completed......................................
2025-10-27 12:39:30,192:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:30,192:INFO:Creating metrics dataframe
2025-10-27 12:39:30,197:INFO:Initializing Least Angle Regression
2025-10-27 12:39:30,197:INFO:Total runtime is 0.1787683129310608 minutes
2025-10-27 12:39:30,197:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:30,198:INFO:Initializing create_model()
2025-10-27 12:39:30,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:30,198:INFO:Checking exceptions
2025-10-27 12:39:30,198:INFO:Importing libraries
2025-10-27 12:39:30,198:INFO:Copying training dataset
2025-10-27 12:39:30,231:INFO:Defining folds
2025-10-27 12:39:30,231:INFO:Declaring metric variables
2025-10-27 12:39:30,231:INFO:Importing untrained model
2025-10-27 12:39:30,231:INFO:Least Angle Regression Imported successfully
2025-10-27 12:39:30,231:INFO:Starting cross validation
2025-10-27 12:39:30,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:30,495:INFO:Calculating mean and std
2025-10-27 12:39:30,496:INFO:Creating metrics dataframe
2025-10-27 12:39:30,498:INFO:Uploading results into container
2025-10-27 12:39:30,498:INFO:Uploading model into container now
2025-10-27 12:39:30,499:INFO:_master_model_container: 5
2025-10-27 12:39:30,499:INFO:_display_container: 2
2025-10-27 12:39:30,499:INFO:Lars(random_state=42)
2025-10-27 12:39:30,499:INFO:create_model() successfully completed......................................
2025-10-27 12:39:30,621:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:30,621:INFO:Creating metrics dataframe
2025-10-27 12:39:30,623:INFO:Initializing Lasso Least Angle Regression
2025-10-27 12:39:30,623:INFO:Total runtime is 0.18586820761362713 minutes
2025-10-27 12:39:30,623:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:30,623:INFO:Initializing create_model()
2025-10-27 12:39:30,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:30,623:INFO:Checking exceptions
2025-10-27 12:39:30,623:INFO:Importing libraries
2025-10-27 12:39:30,623:INFO:Copying training dataset
2025-10-27 12:39:30,651:INFO:Defining folds
2025-10-27 12:39:30,651:INFO:Declaring metric variables
2025-10-27 12:39:30,651:INFO:Importing untrained model
2025-10-27 12:39:30,651:INFO:Lasso Least Angle Regression Imported successfully
2025-10-27 12:39:30,651:INFO:Starting cross validation
2025-10-27 12:39:30,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:30,844:INFO:Calculating mean and std
2025-10-27 12:39:30,844:INFO:Creating metrics dataframe
2025-10-27 12:39:30,846:INFO:Uploading results into container
2025-10-27 12:39:30,846:INFO:Uploading model into container now
2025-10-27 12:39:30,847:INFO:_master_model_container: 6
2025-10-27 12:39:30,847:INFO:_display_container: 2
2025-10-27 12:39:30,847:INFO:LassoLars(random_state=42)
2025-10-27 12:39:30,847:INFO:create_model() successfully completed......................................
2025-10-27 12:39:30,966:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:30,966:INFO:Creating metrics dataframe
2025-10-27 12:39:30,968:INFO:Initializing Orthogonal Matching Pursuit
2025-10-27 12:39:30,968:INFO:Total runtime is 0.19161827564239503 minutes
2025-10-27 12:39:30,968:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:30,969:INFO:Initializing create_model()
2025-10-27 12:39:30,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:30,969:INFO:Checking exceptions
2025-10-27 12:39:30,969:INFO:Importing libraries
2025-10-27 12:39:30,969:INFO:Copying training dataset
2025-10-27 12:39:30,997:INFO:Defining folds
2025-10-27 12:39:30,997:INFO:Declaring metric variables
2025-10-27 12:39:30,998:INFO:Importing untrained model
2025-10-27 12:39:30,998:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-27 12:39:30,998:INFO:Starting cross validation
2025-10-27 12:39:30,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:31,194:INFO:Calculating mean and std
2025-10-27 12:39:31,195:INFO:Creating metrics dataframe
2025-10-27 12:39:31,197:INFO:Uploading results into container
2025-10-27 12:39:31,199:INFO:Uploading model into container now
2025-10-27 12:39:31,199:INFO:_master_model_container: 7
2025-10-27 12:39:31,199:INFO:_display_container: 2
2025-10-27 12:39:31,200:INFO:OrthogonalMatchingPursuit()
2025-10-27 12:39:31,200:INFO:create_model() successfully completed......................................
2025-10-27 12:39:31,315:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:31,315:INFO:Creating metrics dataframe
2025-10-27 12:39:31,317:INFO:Initializing Bayesian Ridge
2025-10-27 12:39:31,317:INFO:Total runtime is 0.19743489821751914 minutes
2025-10-27 12:39:31,317:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:31,318:INFO:Initializing create_model()
2025-10-27 12:39:31,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:31,318:INFO:Checking exceptions
2025-10-27 12:39:31,318:INFO:Importing libraries
2025-10-27 12:39:31,318:INFO:Copying training dataset
2025-10-27 12:39:31,344:INFO:Defining folds
2025-10-27 12:39:31,345:INFO:Declaring metric variables
2025-10-27 12:39:31,345:INFO:Importing untrained model
2025-10-27 12:39:31,345:INFO:Bayesian Ridge Imported successfully
2025-10-27 12:39:31,345:INFO:Starting cross validation
2025-10-27 12:39:31,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:31,571:INFO:Calculating mean and std
2025-10-27 12:39:31,572:INFO:Creating metrics dataframe
2025-10-27 12:39:31,573:INFO:Uploading results into container
2025-10-27 12:39:31,573:INFO:Uploading model into container now
2025-10-27 12:39:31,574:INFO:_master_model_container: 8
2025-10-27 12:39:31,574:INFO:_display_container: 2
2025-10-27 12:39:31,574:INFO:BayesianRidge()
2025-10-27 12:39:31,575:INFO:create_model() successfully completed......................................
2025-10-27 12:39:31,695:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:31,696:INFO:Creating metrics dataframe
2025-10-27 12:39:31,698:INFO:Initializing Passive Aggressive Regressor
2025-10-27 12:39:31,698:INFO:Total runtime is 0.20378491481145225 minutes
2025-10-27 12:39:31,699:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:31,699:INFO:Initializing create_model()
2025-10-27 12:39:31,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:31,699:INFO:Checking exceptions
2025-10-27 12:39:31,699:INFO:Importing libraries
2025-10-27 12:39:31,699:INFO:Copying training dataset
2025-10-27 12:39:31,726:INFO:Defining folds
2025-10-27 12:39:31,726:INFO:Declaring metric variables
2025-10-27 12:39:31,727:INFO:Importing untrained model
2025-10-27 12:39:31,727:INFO:Passive Aggressive Regressor Imported successfully
2025-10-27 12:39:31,727:INFO:Starting cross validation
2025-10-27 12:39:31,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:31,918:INFO:Calculating mean and std
2025-10-27 12:39:31,918:INFO:Creating metrics dataframe
2025-10-27 12:39:31,920:INFO:Uploading results into container
2025-10-27 12:39:31,920:INFO:Uploading model into container now
2025-10-27 12:39:31,921:INFO:_master_model_container: 9
2025-10-27 12:39:31,921:INFO:_display_container: 2
2025-10-27 12:39:31,921:INFO:PassiveAggressiveRegressor(random_state=42)
2025-10-27 12:39:31,921:INFO:create_model() successfully completed......................................
2025-10-27 12:39:32,039:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:32,039:INFO:Creating metrics dataframe
2025-10-27 12:39:32,043:INFO:Initializing Huber Regressor
2025-10-27 12:39:32,043:INFO:Total runtime is 0.20953575770060223 minutes
2025-10-27 12:39:32,043:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:32,043:INFO:Initializing create_model()
2025-10-27 12:39:32,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:32,044:INFO:Checking exceptions
2025-10-27 12:39:32,044:INFO:Importing libraries
2025-10-27 12:39:32,044:INFO:Copying training dataset
2025-10-27 12:39:32,069:INFO:Defining folds
2025-10-27 12:39:32,070:INFO:Declaring metric variables
2025-10-27 12:39:32,070:INFO:Importing untrained model
2025-10-27 12:39:32,070:INFO:Huber Regressor Imported successfully
2025-10-27 12:39:32,070:INFO:Starting cross validation
2025-10-27 12:39:32,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:34,664:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:34,688:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,098:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,161:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,171:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,177:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,227:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,265:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,280:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,289:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-27 12:39:35,315:INFO:Calculating mean and std
2025-10-27 12:39:35,316:INFO:Creating metrics dataframe
2025-10-27 12:39:35,317:INFO:Uploading results into container
2025-10-27 12:39:35,318:INFO:Uploading model into container now
2025-10-27 12:39:35,318:INFO:_master_model_container: 10
2025-10-27 12:39:35,318:INFO:_display_container: 2
2025-10-27 12:39:35,318:INFO:HuberRegressor()
2025-10-27 12:39:35,318:INFO:create_model() successfully completed......................................
2025-10-27 12:39:35,448:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:35,448:INFO:Creating metrics dataframe
2025-10-27 12:39:35,450:INFO:Initializing K Neighbors Regressor
2025-10-27 12:39:35,450:INFO:Total runtime is 0.2663188378016154 minutes
2025-10-27 12:39:35,451:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:35,451:INFO:Initializing create_model()
2025-10-27 12:39:35,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:35,451:INFO:Checking exceptions
2025-10-27 12:39:35,451:INFO:Importing libraries
2025-10-27 12:39:35,451:INFO:Copying training dataset
2025-10-27 12:39:35,480:INFO:Defining folds
2025-10-27 12:39:35,480:INFO:Declaring metric variables
2025-10-27 12:39:35,480:INFO:Importing untrained model
2025-10-27 12:39:35,481:INFO:K Neighbors Regressor Imported successfully
2025-10-27 12:39:35,481:INFO:Starting cross validation
2025-10-27 12:39:35,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:35,672:INFO:Calculating mean and std
2025-10-27 12:39:35,673:INFO:Creating metrics dataframe
2025-10-27 12:39:35,674:INFO:Uploading results into container
2025-10-27 12:39:35,676:INFO:Uploading model into container now
2025-10-27 12:39:35,676:INFO:_master_model_container: 11
2025-10-27 12:39:35,676:INFO:_display_container: 2
2025-10-27 12:39:35,677:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-27 12:39:35,677:INFO:create_model() successfully completed......................................
2025-10-27 12:39:35,787:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:35,787:INFO:Creating metrics dataframe
2025-10-27 12:39:35,789:INFO:Initializing Decision Tree Regressor
2025-10-27 12:39:35,789:INFO:Total runtime is 0.2719682256380717 minutes
2025-10-27 12:39:35,789:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:35,789:INFO:Initializing create_model()
2025-10-27 12:39:35,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:35,789:INFO:Checking exceptions
2025-10-27 12:39:35,789:INFO:Importing libraries
2025-10-27 12:39:35,789:INFO:Copying training dataset
2025-10-27 12:39:35,823:INFO:Defining folds
2025-10-27 12:39:35,824:INFO:Declaring metric variables
2025-10-27 12:39:35,824:INFO:Importing untrained model
2025-10-27 12:39:35,824:INFO:Decision Tree Regressor Imported successfully
2025-10-27 12:39:35,825:INFO:Starting cross validation
2025-10-27 12:39:35,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:36,001:INFO:Calculating mean and std
2025-10-27 12:39:36,002:INFO:Creating metrics dataframe
2025-10-27 12:39:36,003:INFO:Uploading results into container
2025-10-27 12:39:36,003:INFO:Uploading model into container now
2025-10-27 12:39:36,004:INFO:_master_model_container: 12
2025-10-27 12:39:36,004:INFO:_display_container: 2
2025-10-27 12:39:36,004:INFO:DecisionTreeRegressor(random_state=42)
2025-10-27 12:39:36,004:INFO:create_model() successfully completed......................................
2025-10-27 12:39:36,120:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:36,120:INFO:Creating metrics dataframe
2025-10-27 12:39:36,121:INFO:Initializing Random Forest Regressor
2025-10-27 12:39:36,121:INFO:Total runtime is 0.2775021076202393 minutes
2025-10-27 12:39:36,122:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:36,122:INFO:Initializing create_model()
2025-10-27 12:39:36,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:36,122:INFO:Checking exceptions
2025-10-27 12:39:36,122:INFO:Importing libraries
2025-10-27 12:39:36,122:INFO:Copying training dataset
2025-10-27 12:39:36,151:INFO:Defining folds
2025-10-27 12:39:36,151:INFO:Declaring metric variables
2025-10-27 12:39:36,151:INFO:Importing untrained model
2025-10-27 12:39:36,152:INFO:Random Forest Regressor Imported successfully
2025-10-27 12:39:36,152:INFO:Starting cross validation
2025-10-27 12:39:36,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:37,378:INFO:Calculating mean and std
2025-10-27 12:39:37,379:INFO:Creating metrics dataframe
2025-10-27 12:39:37,381:INFO:Uploading results into container
2025-10-27 12:39:37,381:INFO:Uploading model into container now
2025-10-27 12:39:37,382:INFO:_master_model_container: 13
2025-10-27 12:39:37,382:INFO:_display_container: 2
2025-10-27 12:39:37,382:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-10-27 12:39:37,382:INFO:create_model() successfully completed......................................
2025-10-27 12:39:37,504:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:37,504:INFO:Creating metrics dataframe
2025-10-27 12:39:37,506:INFO:Initializing Extra Trees Regressor
2025-10-27 12:39:37,506:INFO:Total runtime is 0.300585416952769 minutes
2025-10-27 12:39:37,506:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:37,506:INFO:Initializing create_model()
2025-10-27 12:39:37,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:37,506:INFO:Checking exceptions
2025-10-27 12:39:37,506:INFO:Importing libraries
2025-10-27 12:39:37,506:INFO:Copying training dataset
2025-10-27 12:39:37,535:INFO:Defining folds
2025-10-27 12:39:37,535:INFO:Declaring metric variables
2025-10-27 12:39:37,535:INFO:Importing untrained model
2025-10-27 12:39:37,535:INFO:Extra Trees Regressor Imported successfully
2025-10-27 12:39:37,535:INFO:Starting cross validation
2025-10-27 12:39:37,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:38,903:INFO:Calculating mean and std
2025-10-27 12:39:38,904:INFO:Creating metrics dataframe
2025-10-27 12:39:38,912:INFO:Uploading results into container
2025-10-27 12:39:38,914:INFO:Uploading model into container now
2025-10-27 12:39:38,915:INFO:_master_model_container: 14
2025-10-27 12:39:38,915:INFO:_display_container: 2
2025-10-27 12:39:38,916:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-10-27 12:39:38,916:INFO:create_model() successfully completed......................................
2025-10-27 12:39:39,045:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:39,045:INFO:Creating metrics dataframe
2025-10-27 12:39:39,048:INFO:Initializing AdaBoost Regressor
2025-10-27 12:39:39,048:INFO:Total runtime is 0.3262848854064942 minutes
2025-10-27 12:39:39,048:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:39,048:INFO:Initializing create_model()
2025-10-27 12:39:39,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:39,048:INFO:Checking exceptions
2025-10-27 12:39:39,048:INFO:Importing libraries
2025-10-27 12:39:39,048:INFO:Copying training dataset
2025-10-27 12:39:39,077:INFO:Defining folds
2025-10-27 12:39:39,077:INFO:Declaring metric variables
2025-10-27 12:39:39,077:INFO:Importing untrained model
2025-10-27 12:39:39,078:INFO:AdaBoost Regressor Imported successfully
2025-10-27 12:39:39,078:INFO:Starting cross validation
2025-10-27 12:39:39,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:39,554:INFO:Calculating mean and std
2025-10-27 12:39:39,555:INFO:Creating metrics dataframe
2025-10-27 12:39:39,556:INFO:Uploading results into container
2025-10-27 12:39:39,557:INFO:Uploading model into container now
2025-10-27 12:39:39,557:INFO:_master_model_container: 15
2025-10-27 12:39:39,557:INFO:_display_container: 2
2025-10-27 12:39:39,558:INFO:AdaBoostRegressor(random_state=42)
2025-10-27 12:39:39,558:INFO:create_model() successfully completed......................................
2025-10-27 12:39:39,682:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:39,682:INFO:Creating metrics dataframe
2025-10-27 12:39:39,684:INFO:Initializing Gradient Boosting Regressor
2025-10-27 12:39:39,684:INFO:Total runtime is 0.33688540856043503 minutes
2025-10-27 12:39:39,684:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:39,684:INFO:Initializing create_model()
2025-10-27 12:39:39,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:39,684:INFO:Checking exceptions
2025-10-27 12:39:39,684:INFO:Importing libraries
2025-10-27 12:39:39,684:INFO:Copying training dataset
2025-10-27 12:39:39,713:INFO:Defining folds
2025-10-27 12:39:39,713:INFO:Declaring metric variables
2025-10-27 12:39:39,713:INFO:Importing untrained model
2025-10-27 12:39:39,714:INFO:Gradient Boosting Regressor Imported successfully
2025-10-27 12:39:39,714:INFO:Starting cross validation
2025-10-27 12:39:39,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:40,432:INFO:Calculating mean and std
2025-10-27 12:39:40,433:INFO:Creating metrics dataframe
2025-10-27 12:39:40,435:INFO:Uploading results into container
2025-10-27 12:39:40,435:INFO:Uploading model into container now
2025-10-27 12:39:40,436:INFO:_master_model_container: 16
2025-10-27 12:39:40,436:INFO:_display_container: 2
2025-10-27 12:39:40,436:INFO:GradientBoostingRegressor(random_state=42)
2025-10-27 12:39:40,436:INFO:create_model() successfully completed......................................
2025-10-27 12:39:40,553:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:40,553:INFO:Creating metrics dataframe
2025-10-27 12:39:40,555:INFO:Initializing Extreme Gradient Boosting
2025-10-27 12:39:40,555:INFO:Total runtime is 0.3514021039009095 minutes
2025-10-27 12:39:40,555:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:40,555:INFO:Initializing create_model()
2025-10-27 12:39:40,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:40,555:INFO:Checking exceptions
2025-10-27 12:39:40,555:INFO:Importing libraries
2025-10-27 12:39:40,555:INFO:Copying training dataset
2025-10-27 12:39:40,587:INFO:Defining folds
2025-10-27 12:39:40,587:INFO:Declaring metric variables
2025-10-27 12:39:40,587:INFO:Importing untrained model
2025-10-27 12:39:40,587:INFO:Extreme Gradient Boosting Imported successfully
2025-10-27 12:39:40,588:INFO:Starting cross validation
2025-10-27 12:39:40,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:41,196:INFO:Calculating mean and std
2025-10-27 12:39:41,197:INFO:Creating metrics dataframe
2025-10-27 12:39:41,200:INFO:Uploading results into container
2025-10-27 12:39:41,201:INFO:Uploading model into container now
2025-10-27 12:39:41,201:INFO:_master_model_container: 17
2025-10-27 12:39:41,201:INFO:_display_container: 2
2025-10-27 12:39:41,202:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-10-27 12:39:41,202:INFO:create_model() successfully completed......................................
2025-10-27 12:39:41,320:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:41,320:INFO:Creating metrics dataframe
2025-10-27 12:39:41,322:INFO:Initializing Light Gradient Boosting Machine
2025-10-27 12:39:41,322:INFO:Total runtime is 0.3641854921976726 minutes
2025-10-27 12:39:41,322:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:41,322:INFO:Initializing create_model()
2025-10-27 12:39:41,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:41,322:INFO:Checking exceptions
2025-10-27 12:39:41,322:INFO:Importing libraries
2025-10-27 12:39:41,322:INFO:Copying training dataset
2025-10-27 12:39:41,353:INFO:Defining folds
2025-10-27 12:39:41,353:INFO:Declaring metric variables
2025-10-27 12:39:41,353:INFO:Importing untrained model
2025-10-27 12:39:41,353:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-27 12:39:41,353:INFO:Starting cross validation
2025-10-27 12:39:41,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:42,509:INFO:Calculating mean and std
2025-10-27 12:39:42,510:INFO:Creating metrics dataframe
2025-10-27 12:39:42,513:INFO:Uploading results into container
2025-10-27 12:39:42,514:INFO:Uploading model into container now
2025-10-27 12:39:42,514:INFO:_master_model_container: 18
2025-10-27 12:39:42,515:INFO:_display_container: 2
2025-10-27 12:39:42,515:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-10-27 12:39:42,515:INFO:create_model() successfully completed......................................
2025-10-27 12:39:42,655:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:42,655:INFO:Creating metrics dataframe
2025-10-27 12:39:42,658:INFO:Initializing Dummy Regressor
2025-10-27 12:39:42,658:INFO:Total runtime is 0.3864497820536296 minutes
2025-10-27 12:39:42,658:INFO:SubProcess create_model() called ==================================
2025-10-27 12:39:42,659:INFO:Initializing create_model()
2025-10-27 12:39:42,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014643027130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:42,659:INFO:Checking exceptions
2025-10-27 12:39:42,659:INFO:Importing libraries
2025-10-27 12:39:42,659:INFO:Copying training dataset
2025-10-27 12:39:42,690:INFO:Defining folds
2025-10-27 12:39:42,690:INFO:Declaring metric variables
2025-10-27 12:39:42,690:INFO:Importing untrained model
2025-10-27 12:39:42,691:INFO:Dummy Regressor Imported successfully
2025-10-27 12:39:42,691:INFO:Starting cross validation
2025-10-27 12:39:42,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-27 12:39:42,870:INFO:Calculating mean and std
2025-10-27 12:39:42,871:INFO:Creating metrics dataframe
2025-10-27 12:39:42,872:INFO:Uploading results into container
2025-10-27 12:39:42,872:INFO:Uploading model into container now
2025-10-27 12:39:42,873:INFO:_master_model_container: 19
2025-10-27 12:39:42,873:INFO:_display_container: 2
2025-10-27 12:39:42,873:INFO:DummyRegressor()
2025-10-27 12:39:42,873:INFO:create_model() successfully completed......................................
2025-10-27 12:39:42,987:INFO:SubProcess create_model() end ==================================
2025-10-27 12:39:42,987:INFO:Creating metrics dataframe
2025-10-27 12:39:42,989:WARNING:C:\Users\Public\Documents\Adobe\Python\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-10-27 12:39:42,991:INFO:Initializing create_model()
2025-10-27 12:39:42,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014640492DA0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-27 12:39:42,991:INFO:Checking exceptions
2025-10-27 12:39:42,992:INFO:Importing libraries
2025-10-27 12:39:42,992:INFO:Copying training dataset
2025-10-27 12:39:43,027:INFO:Defining folds
2025-10-27 12:39:43,027:INFO:Declaring metric variables
2025-10-27 12:39:43,028:INFO:Importing untrained model
2025-10-27 12:39:43,028:INFO:Declaring custom model
2025-10-27 12:39:43,029:INFO:Extreme Gradient Boosting Imported successfully
2025-10-27 12:39:43,030:INFO:Cross validation set to False
2025-10-27 12:39:43,030:INFO:Fitting Model
2025-10-27 12:39:43,190:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-10-27 12:39:43,190:INFO:create_model() successfully completed......................................
2025-10-27 12:39:43,340:INFO:_master_model_container: 19
2025-10-27 12:39:43,341:INFO:_display_container: 2
2025-10-27 12:39:43,342:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-10-27 12:39:43,342:INFO:compare_models() successfully completed......................................
